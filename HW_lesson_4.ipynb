{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70d1cd2",
   "metadata": {},
   "source": [
    "## Урок 4. Оценка и интерпретация полученной модели. Курсовой проект (<a href='https://github.com/Kambey-san/Libs_DS_Python_continue/blob/Course_project/%D0%A1ourse%20project/A.Konyaev_%D0%A1ourse_project.ipynb'>ссылка</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9ecd6",
   "metadata": {},
   "source": [
    "### Домашняя работа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26517436",
   "metadata": {},
   "source": [
    "*1. Расскажите, как работает регуляризация в решающих деревьях, какие параметры мы штрафуем в данных алгоритмах?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5437c89",
   "metadata": {},
   "source": [
    "#### $L_2$-регуляризация (ridge, регуляризация Тихонова)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62255a00",
   "metadata": {
    "id": "8Zgvr4aEiqut"
   },
   "source": [
    "Метод регуляризации заключается в \"штрафовании\" модели за слишком большие **веса** путем добавления нового члена к ошибке:\n",
    "\n",
    "$$Q(w, X) + \\lambda ||w||^{2} \\rightarrow \\underset{w}{\\text{min}}.$$\n",
    "\n",
    "добавленный член $\\lambda ||w||^{2}$ - **квадратичный регуляризатор**, который представляет собой $L_{2}$-норму вектора весов, то есть сумму квадратов весов $\\sum^{d}_{j=1}w_{j}^{2}$, коэффициент $\\lambda$ при нем - коэффициент регуляризации. Чем больше его значение, тем меньшая сложность модели будет получаться в процессе такого обучения. Если _увеличивать_ его, в какой-то момент оптимальным для модели окажется зануление всех весов. В то же время при слишком _низких_ его значениях появляется вероятность чрезмерного усложнения модели и переобучения. Выбор оптимального значения этого коэфициента является отдельной задачей и заключается в многократном обучении модели с разными его значениями и сравнении их качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501e96c9",
   "metadata": {},
   "source": [
    "#### $L_1$-регуляризация (lasso, регуляризация через манхэттенское расстояние)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f5285",
   "metadata": {
    "id": "-OTMLxupiquu"
   },
   "source": [
    "Описанный выше метод с использованием $L_{2}$-нормы вектора весов в качестве регуляризатора называется **$L_{2}$-регуляризацией**. По аналогии существует также **$L_{1}$-регуляризация**, использующая в качестве регуляризатора $L_{1}$-норму вектора весов, то есть сумму модулей весов.\n",
    "\n",
    "$$||w||_{1} = \\sum^{d}_{j=1}|w_{j}|.$$\n",
    "\n",
    "Такой метод часто используется для отбора признаков: у менее ценных признаков гораздо раньше обнуляются веса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee0db0",
   "metadata": {},
   "source": [
    "*2. По какому принципу рассчитывается \"важность признака (feature_importance)\" в ансамблях деревьев?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e6332",
   "metadata": {},
   "source": [
    "Атрибут **feature_importance** в scikit-learn сообщает об относительной важности каждого признака. Чем выше значение, тем важнее признак (сумма всех значений равна 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682924d6",
   "metadata": {},
   "source": [
    "### <a href='https://github.com/Kambey-san/Libs_DS_Python_continue/blob/Course_project/%D0%A1ourse%20project/A.Konyaev_%D0%A1ourse_project.ipynb'>Ссылка на курсовой проект</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
